# Code For Generative Model Training

In the Repository you will find information about different ways to fine-tune a Generative LLM. Also other resources.
1. ***Basic fine-tuning***: Basic code to train a small casual model on prompt, response toy data.
2. ***Fine-Tuning using Wiki Dataset***: Train on WIKI dataset using casual approach for ***Text Generation*** task.
3. ***Model Distilled***: Model Distillation from a teacher model(GPT2-medium) to Student Model(GPT-2)
